> Designing the algorithm in paper before implementing it

> Analyze the algorithm according to O, time and space after writing the algoritm

> Alg cant take 0 or more args but must return a value

Design algoritms with parallelism in mind

When calculating the time it takes for O(n) to execute, we must also take into account the time it takes for the computer/compiler/lang to execute.
For example, at best case scenario for a code written in machine-code algorithm A could take around 2 instructions to produce an output. Say if algoritm A is using a sorting algorithm, thus taking O(n^2) to complete the task, we could calculate the time it takes for algorithm A to produce an output like this:

each pc is tryin to process 10 million numbers.
(A can process 10 billioin instructions per second)

2.(10^7)^2 instructions < 2 + O(n^2) 
______________________ == 20,000 seconds
10^10 instructions/sec

Say that computer B takes 10 million intructions per second, using merge sort (nlog(n)), say that computer b takes a high level language that uses 50 instructions to produce an output.

50.10^7 log 10^7 instrct
________________________ == 1163 seconds
10^7 instructions/second
















